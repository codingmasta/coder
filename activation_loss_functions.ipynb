{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtwA_LbDVkt9"
      },
      "source": [
        "# Train and test models on the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VeOsugMVkt_"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wyw53ZypVkuA"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "input_dim = 784  # 28*28\n",
        "output_dim = nb_classes = 10\n",
        "batch_size = 128\n",
        "nb_epoch = 20\n",
        "\n",
        "X_train = X_train.reshape(60000, input_dim)\n",
        "X_test = X_test.reshape(10000, input_dim)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGYKpwl-VkuA"
      },
      "outputs": [],
      "source": [
        "Y_train = to_categorical(y_train, nb_classes)\n",
        "Y_test = to_categorical(y_test, nb_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DDFWIEMVkuA"
      },
      "source": [
        "## 1. In this task, you'll implement several ANN models with different activation functions. Specifically:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvTh5aDNVkuA"
      },
      "source": [
        "### Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using tanh activation function for each layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3KfCvWQVkuB",
        "outputId": "c12e902d-7342-4828-c2af-7f5094b7e603"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /Users/mladmin/miniconda3/envs/datascience/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /Users/mladmin/miniconda3/envs/datascience/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 1.0228 - acc: 0.7473\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.5206 - acc: 0.8713\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.4206 - acc: 0.8896\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.3729 - acc: 0.8995\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.3436 - acc: 0.9051\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.3228 - acc: 0.9100\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.3067 - acc: 0.9136\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.2937 - acc: 0.9171\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.2824 - acc: 0.9198\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.2726 - acc: 0.92260s - loss: 0.2794 - \n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.2640 - acc: 0.9248\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.2560 - acc: 0.9271\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.2488 - acc: 0.9293\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2420 - acc: 0.9309\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.2357 - acc: 0.9329\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.2297 - acc: 0.9352\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.2241 - acc: 0.9366\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2186 - acc: 0.9384\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2136 - acc: 0.9398\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.2087 - acc: 0.9413\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x10ae2b2b0>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"tanh\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"tanh\"))\n",
        "# last layer is the output layer.\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# setting verbose=1 prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEyWLcsKVkuB",
        "outputId": "d8812ccd-be66-4d70-95f1-4f0ad044a62c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test score: 0.20581834660768508\n",
            "Test accuracy: 0.9423\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nygIJMamVkuC"
      },
      "source": [
        "### Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using sigmoid activation function for each layer.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9S-FiczWVkuC",
        "outputId": "c960842d-ac8f-4bb8-adad-9251d22533df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.2970 - acc: 0.1375\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.2386 - acc: 0.3223\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 2.1797 - acc: 0.4586\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 2.0979 - acc: 0.5424\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 1.9811 - acc: 0.5875\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 1.8232 - acc: 0.6102\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 1.6353 - acc: 0.6439\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 1.4445 - acc: 0.6734\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2761 - acc: 0.7064\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 1.1395 - acc: 0.7325\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0313 - acc: 0.7564\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.9447 - acc: 0.7768\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.8736 - acc: 0.7919\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.8139 - acc: 0.8051\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.7628 - acc: 0.8176\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.7185 - acc: 0.8275\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.6798 - acc: 0.8368\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.6456 - acc: 0.8440\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.6154 - acc: 0.8508\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.5886 - acc: 0.8559\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x1295c3860>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"sigmoid\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"sigmoid\"))\n",
        "# last layer is the output layer.\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# setting verbose=1 prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAYMSnNyVkuC",
        "outputId": "840af938-96e7-4a9d-d1ef-7864831e1599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test score: 0.5598974136829377\n",
            "Test accuracy: 0.863\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0q3l1qPVkuC"
      },
      "source": [
        "### Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using ReLU activation function for each layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLQJeOkVVkuD",
        "outputId": "66215768-22be-454e-f970-488bd1081b22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 1.2379 - acc: 0.6780\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.5055 - acc: 0.8667\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.3917 - acc: 0.8912\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.3436 - acc: 0.9024\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.3140 - acc: 0.9106\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 1s 17us/sample - loss: 0.2926 - acc: 0.9163\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2753 - acc: 0.9217\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2607 - acc: 0.9250\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2482 - acc: 0.9293\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2373 - acc: 0.9320\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2275 - acc: 0.9355\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2186 - acc: 0.9375\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2103 - acc: 0.9396\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2033 - acc: 0.9422\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.1963 - acc: 0.9449\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.1901 - acc: 0.9464\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.1841 - acc: 0.9478\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.1786 - acc: 0.9499\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.1735 - acc: 0.9510\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.1684 - acc: 0.9527\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x13538b898>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# last layer is the output layer.\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# setting verbose=1 prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdftHGzqVkuD",
        "outputId": "e0ce9f83-b90e-4c5d-8682-0698865c5bf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test score: 0.17043185496479274\n",
            "Test accuracy: 0.9502\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXOZle8dVkuD"
      },
      "source": [
        "### Compare the result of each model with each other. Which activation function did perform better?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha-ocPIyVkuD"
      },
      "source": [
        "The highest accuracies in both the training and the test sets are achieved using the ReLU function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zeN85UpVkuD"
      },
      "source": [
        "## 2. In this task, you'll implement the ANN models specified below with the hinge loss function as their loss functions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aKuZe2nVkuD"
      },
      "source": [
        "### Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using tanh activation function for each layer.\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhpEaQsZVkuD",
        "outputId": "27b6b8b9-8f5d-4800-9567-cd59262270ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /Users/mladmin/miniconda3/envs/datascience/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.9903 - acc: 0.4577\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.7698 - acc: 0.7298\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.5670 - acc: 0.8071\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.4495 - acc: 0.8494\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.3799 - acc: 0.8667\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.3367 - acc: 0.87730s - loss: 0.343\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.3075 - acc: 0.8838\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.2862 - acc: 0.88950s - loss: 0.2907 - acc\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.2698 - acc: 0.8939\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.2567 - acc: 0.8979\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2459 - acc: 0.9009\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2368 - acc: 0.9040\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.2289 - acc: 0.9064\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2221 - acc: 0.9084\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2161 - acc: 0.9105\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2106 - acc: 0.9123\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2058 - acc: 0.91360s - loss: 0.2079 - ac\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2012 - acc: 0.9155\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.1972 - acc: 0.9168\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.1933 - acc: 0.9183\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x136081a58>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"tanh\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"tanh\"))\n",
        "# last layer is the output layer.\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_hinge',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# setting verbose=1 prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pskytyjhVkuE",
        "outputId": "68585f0b-24bb-4119-b014-b1bead1e2abd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test score: 0.1860966409087181\n",
            "Test accuracy: 0.922\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qo43QBUVkuE"
      },
      "source": [
        "### Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using sigmoid activation function for each layer.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQHGGZ4ZVkuE",
        "outputId": "2559afb0-79cc-470a-f0c9-3fbd906cb0c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 1.0201 - acc: 0.1113\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 1.0068 - acc: 0.14210s - loss: 1.0082 - a - ETA: 0s - loss: 1.0072 - acc: 0.\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 1.0027 - acc: 0.1726\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 1.0022 - acc: 0.2194\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 1.0018 - acc: 0.2748\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 1.0014 - acc: 0.3288\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0010 - acc: 0.3791\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0006 - acc: 0.4281\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0003 - acc: 0.4673\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0000 - acc: 0.5016\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.9997 - acc: 0.5300\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.9995 - acc: 0.55490s - loss: 0.9\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.9992 - acc: 0.5764\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.9989 - acc: 0.5945\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.9987 - acc: 0.6097\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.9985 - acc: 0.6230\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.9982 - acc: 0.63510s - loss: 0.9982 - acc: 0.6\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.9980 - acc: 0.6454\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.9978 - acc: 0.6543\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.9975 - acc: 0.6619\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x135d5e6a0>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"sigmoid\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"sigmoid\"))\n",
        "# last layer is the output layer.\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_hinge',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# setting verbose=1 prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3dqsGD8VkuE",
        "outputId": "b8fccdfd-92b2-4d63-d2a8-60158f4b1b20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test score: 0.9972937772750855\n",
            "Test accuracy: 0.6791\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqewUAjcVkuE"
      },
      "source": [
        "### Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using ReLU activation function for each layer.\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWSQg7c9VkuE",
        "outputId": "e348ded3-4bb1-4313-9f3a-7d74cad7e952"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 1.0131 - acc: 0.3226\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.9804 - acc: 0.5610\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.8974 - acc: 0.6470\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.7062 - acc: 0.7256\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.5146 - acc: 0.8270\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.3895 - acc: 0.86840s - loss: 0.4028 - acc:\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.3205 - acc: 0.88210s - loss: 0.3294 - ac\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2827 - acc: 0.8902\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.2588 - acc: 0.8956\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2419 - acc: 0.9001\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2293 - acc: 0.9044\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2191 - acc: 0.9068\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2106 - acc: 0.9099\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2035 - acc: 0.9124\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.1973 - acc: 0.9144\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.1917 - acc: 0.9164\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.1870 - acc: 0.9181\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.1824 - acc: 0.9199\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.1783 - acc: 0.9213\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.1745 - acc: 0.9229\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x137052f60>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# last layer is the output layer.\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_hinge',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# setting verbose=1 prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZ1dQQM9VkuF",
        "outputId": "0bcb8abc-dd8e-4ccd-bcde-b38a8722dbd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test score: 0.16739646133184433\n",
            "Test accuracy: 0.9261\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tASPaZgRVkuF"
      },
      "source": [
        "### Compare the result of each model with the result of the same model from the previous task. Which loss function did perform better?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osRQdhAmVkuF"
      },
      "source": [
        "The highest accuracies in both the training and the test sets are achieved using the ReLU function. Moreover, all accuracies for all the models are lower when we train our models using hinge loss in comparison to using cross entropy loss."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}